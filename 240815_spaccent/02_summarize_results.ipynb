{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "210d8635-8be2-4846-a7a6-a29db50c4843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import scipy.stats as st\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/shoahoshoaho/Git/cuhksz-phd/sho_util/pyfiles/\")\n",
    "from basic import get_bool_base_on_conditions\n",
    "\n",
    "def get_json(path):\n",
    "    with open(path, 'r') as j:\n",
    "         contents = json.loads(j.read())\n",
    "    return contents\n",
    "\n",
    "sr = 16000\n",
    "result_base_dir = \"./audio/20240815_spaccent/\"\n",
    "\n",
    "experiments = {\n",
    "    \"hindi\": [\n",
    "        \"CMU-ARCTIC/SLT\",\n",
    "        \"PD-AST/SLT/English\",\n",
    "        \"L2-ARCTIC/ASI\",\n",
    "        \"L2-ARCTIC/TNI\",\n",
    "        \"PD-AST/SLT/Hindi\",\n",
    "        \"PD-AST/ASI/Hindi\",\n",
    "        \"PD-AST/TNI/Hindi\",\n",
    "        \"VTN_fine-tuning_nocondition_gt2syn_hifiganmelhifiganmel_hubert_norepeating/100000\",\n",
    "        \"VTN_fine-tuning_nocondition_mix2synVCTK3hr_hifiganmelhifiganmel_hubert_norepeating/100000\",\n",
    "    ],\n",
    "    \"korean\": [\n",
    "        \"CMU-ARCTIC/SLT\",\n",
    "        \"PD-AST/SLT/English\",\n",
    "        \"L2-ARCTIC/HKK\",\n",
    "        \"L2-ARCTIC/YDCK\",\n",
    "        \"PD-AST/SLT/Korean\",\n",
    "        \"PD-AST/HKK/Korean\",\n",
    "        \"PD-AST/YDCK/Korean\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3b45315-7a33-4411-b530-968403dc056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_control_result(contents, name, sampleid, segment):\n",
    "    arrays = []\n",
    "    for idx, a in enumerate(contents):\n",
    "        if idx>=48:\n",
    "            continue\n",
    "        mn, fileid, emotion = a[\"TestID\"].split(\"---\")[-3:]\n",
    "        allocation = {item[0]: item[2] for item in a[\"PresentationOrder\"].split(\", \")}\n",
    "        res = [allocation[key] for key in a[\"Preference\"]]\n",
    "        array = [mn, fileid, emotion, *res]\n",
    "        arrays += [array]\n",
    "\n",
    "    columns = [\"model name\", \"file id\", \"emotion\", \"Lowest Prediction\", \"Highest Prediction\"]\n",
    "    sampledf = pd.DataFrame(np.array(arrays), columns=columns)\n",
    "    samplearrays = []\n",
    "    for mn in modelnames:\n",
    "        for fileid in sampledf[\"file id\"].unique():\n",
    "            params = {\"model name\": [mn], \"file id\": [fileid]}\n",
    "            modeldf = sampledf[get_bool_base_on_conditions(sampledf, params)]\n",
    "            if len(modeldf)>0:\n",
    "                int_array = []\n",
    "                for emotion in emos:\n",
    "                    params = {\"emotion\": [emotion]}\n",
    "                    emotiondf = modeldf[get_bool_base_on_conditions(modeldf, params)]\n",
    "                    a = [(emotiondf[\"Lowest Prediction\"]==label).sum() for label in intensitylabels]\n",
    "                    b = [(emotiondf[\"Highest Prediction\"]==label).sum() for label in intensitylabels]\n",
    "                    int_array += [a + b]\n",
    "                array = list(np.array(int_array).reshape(-1)) + list(np.sum(np.array(int_array), axis=0))\n",
    "            else:\n",
    "                array = [None]*30\n",
    "            samplearrays += [[name, sampleid, fileid, mn, *array]]\n",
    "\n",
    "    columns = []\n",
    "    for cl in [\"Test Name\", \"Test ID\", \"File ID\", \"model name\"]:\n",
    "        columns += [(\"basic\", \"\", cl)]\n",
    "    for emotion in emos + [\"total\"]:\n",
    "        for key in [\"LP\", \"HP\"]:\n",
    "            for label in intensitylabels:\n",
    "                columns += [(f\"{segment}-level control\", emotion, f\"{key}-{label}\")]\n",
    "    result = pd.DataFrame(np.array(samplearrays), columns=pd.MultiIndex.from_tuples(columns))\n",
    "    return result\n",
    "\n",
    "def get_mushra_result(contents, name, sampleid, metric):\n",
    "    arrays = []\n",
    "    for idx, a in enumerate(contents):\n",
    "        if idx>=100:\n",
    "            continue\n",
    "        if len(a)==1:\n",
    "            continue\n",
    "        _, fileid = a[\"TestID\"].split(\"---\")\n",
    "        ratings = a[\"rating\"]\n",
    "        arrays += [[name, sampleid, fileid, key, ratings[key]]for key in ratings]\n",
    "    columns = []\n",
    "    for cl in [\"Test Name\", \"Test ID\", \"File ID\", \"model name\"]:\n",
    "        columns += [(\"basic\",  cl)]\n",
    "    for label in [f\"{metric}\"]:\n",
    "        columns += [(metric, \"score\")]\n",
    "    result = pd.DataFrame(np.array(arrays), columns=pd.MultiIndex.from_tuples(columns))\n",
    "    result.loc[:, [metric]] = result.loc[:, [metric]].values.astype(float)\n",
    "    return result\n",
    "\n",
    "def get_contents(path):\n",
    "    contents = get_json(path)\n",
    "    name = contents[-1][\"UserName\"]\n",
    "    sampleid = path[:-5].split(\"_\")[-1]\n",
    "    return contents, name, sampleid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e367e1b6-73b0-4f3e-bf36-592ea946fe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contents(path):\n",
    "    contents = get_json(path)\n",
    "    name = contents[-1][\"UserName\"]\n",
    "    sampleid = path[:-5].split(\"_\")[-1]\n",
    "    return contents, name, sampleid\n",
    "\n",
    "def get_mushra_result(contents, name, sampleid, metric):\n",
    "    arrays = []\n",
    "    for idx, a in enumerate(contents):\n",
    "        if idx>=100:\n",
    "            continue\n",
    "        if len(a)==1:\n",
    "            continue\n",
    "        _, fileid = a[\"TestID\"].split(\"---\")\n",
    "        ratings = a[\"rating\"]\n",
    "        arrays += [[name, sampleid, fileid, key, ratings[key]]for key in ratings]\n",
    "    columns = []\n",
    "    for cl in [\"Test Name\", \"Test ID\", \"File ID\", \"model name\"]:\n",
    "        columns += [(\"basic\",  cl)]\n",
    "    for label in [f\"{metric}\"]:\n",
    "        columns += [(metric, \"score\")]\n",
    "    result = pd.DataFrame(np.array(arrays), columns=pd.MultiIndex.from_tuples(columns))\n",
    "    result.loc[:, [metric]] = result.loc[:, [metric]].values.astype(float)\n",
    "    return result\n",
    "\n",
    "def get_diffs(result):\n",
    "    diffs = []\n",
    "    params = {(\"basic\", \"model name\"): [a for a in list(set(list(result[(\"basic\", \"model name\")].unique())) - set(excluded_list)) if \"---2\" in a]}\n",
    "    df = result[get_bool_base_on_conditions(result, params, True)]\n",
    "    for array in df.values:\n",
    "        _, _, fileid, mn, _ = array\n",
    "        mn2 = mn.split(\"---\")[0]\n",
    "        params = {(\"basic\", \"File ID\"): [fileid], (\"basic\", \"model name\"):[mn, mn2]}\n",
    "        result[get_bool_base_on_conditions(result, params, True)]\n",
    "        scores = result[get_bool_base_on_conditions(result, params, True)].values[:, -1]\n",
    "        diffs += [np.abs(scores[0]-scores[1])]\n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "02dca659-e64b-49fc-a217-a12ea7328a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reichan ACTHindi 19.875\n",
      "Sho ACTHindi 3.875\n",
      "Sho ACTKorean 11.375\n"
     ]
    }
   ],
   "source": [
    "resultfiles = glob.glob(f\"./web_service/results/*.json\")\n",
    "resultfiles.sort()\n",
    "resultfiles = resultfiles[3:]\n",
    "\n",
    "not_found = []\n",
    "results = {key: [] for key in [\"NATHindi\", \"ACTHindi\", \"NATKorean\", \"ACTKorean\"]}\n",
    "for path in resultfiles:\n",
    "    contents, name, sampleid = get_contents(path)\n",
    "    testtype = contents[0][\"TestID\"].split(\"---\")[0]\n",
    "    if testtype==\"NATHindi\":\n",
    "        result = get_mushra_result(contents, name, sampleid, testtype)\n",
    "    elif testtype==\"ACTHindi\":\n",
    "        result = get_mushra_result(contents, name, sampleid, testtype)\n",
    "    if testtype==\"NATKorean\":\n",
    "        result = get_mushra_result(contents, name, sampleid, testtype)\n",
    "    elif testtype==\"ACTKorean\":\n",
    "        result = get_mushra_result(contents, name, sampleid, testtype)\n",
    "    diffs = get_diffs(result)\n",
    "    print(name, testtype, np.mean(diffs))\n",
    "    result[(\"basic\", \"model name\")] = [a.split(\"---\")[0] for a in result[(\"basic\", \"model name\")].values]\n",
    "    results[testtype] += [result]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79e4bb9-eef7-442b-9d13-57bd22e04635",
   "metadata": {},
   "source": [
    "# Check Individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f463430b-7bbc-4abe-8c2a-d3810bdb7129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sho\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(basic, Test Name)</th>\n",
       "      <th>(basic, model name)</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">Sho</th>\n",
       "      <th>CMU-ARCTIC___SLT</th>\n",
       "      <td>5.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2-ARCTIC___HKK</th>\n",
       "      <td>66.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2-ARCTIC___YDCK</th>\n",
       "      <td>54.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PD-AST___HKK___Korean</th>\n",
       "      <td>82.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PD-AST___SLT___English</th>\n",
       "      <td>12.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PD-AST___SLT___Korean</th>\n",
       "      <td>81.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PD-AST___YDCK___Korean</th>\n",
       "      <td>82.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               score\n",
       "(basic, Test Name) (basic, model name)              \n",
       "Sho                CMU-ARCTIC___SLT         5.375000\n",
       "                   L2-ARCTIC___HKK         66.777778\n",
       "                   L2-ARCTIC___YDCK        54.300000\n",
       "                   PD-AST___HKK___Korean   82.111111\n",
       "                   PD-AST___SLT___English  12.800000\n",
       "                   PD-AST___SLT___Korean   81.888889\n",
       "                   PD-AST___YDCK___Korean  82.777778"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "metric = \"ACTKorean\"\n",
    "\n",
    "result = results[metric][idx]\n",
    "print(result[(\"basic\", \"Test Name\")][0])\n",
    "result.groupby([(\"basic\",\"Test Name\"), (\"basic\",\"model name\")]).mean()[metric]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8c06c5-b23f-4679-8f9f-0b7347afbaf5",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3457e9de-c74e-43fd-92d3-bb2de20d3c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_gradient(val, min_val=-1, max_val=1, color='red'):\n",
    "    if val < min_val: val = min_val\n",
    "    if val > max_val: val = max_val\n",
    "    normalized_val = (val - min_val) / (max_val - min_val)\n",
    "    \n",
    "    if color == 'red':\n",
    "        red_intensity = int(255 * normalized_val)\n",
    "        return f'background-color: rgb({red_intensity}, 0, 0)'\n",
    "    elif color == 'green':\n",
    "        green_intensity = int(255 * normalized_val)\n",
    "        return f'background-color: rgb(0, {green_intensity}, 0)'\n",
    "    elif color == 'blue':\n",
    "        blue_intensity = int(255 * normalized_val)\n",
    "        return f'background-color: rgb(0, 0, {blue_intensity})'\n",
    "    else:\n",
    "        return 'background-color: none'\n",
    "\n",
    "def apply_color_gradient(df, min_val=0, max_val=1.0):\n",
    "    \"\"\"\n",
    "    df.style.apply(lambda x:apply_color_gradient(x, min_val=0, max_val=100), axis=None)\n",
    "    \"\"\"\n",
    "    styles = df.copy()\n",
    "    for col in styles.columns:\n",
    "        color = 'red' if \"LP\" in col else \"green\"\n",
    "        color = \"blue\" if col==\"mean\" else color\n",
    "        styles[col] = df[col].apply(color_gradient, min_val=min_val, max_val=max_val, color=color)\n",
    "    return styles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5402b1fd-653e-461e-bf9c-70303b020e46",
   "metadata": {},
   "source": [
    "- MUSHRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d2f7bb1f-1ff3-4fb8-8151-4b37369b90af",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardization = False\n",
    "excluded_list = []\n",
    "\n",
    "dfdir = {}\n",
    "# for metric in [\"NATHindi\", \"ACTHindi\", \"NATKorean\", \"ACTKorean\"]:\n",
    "for metric in [\"ACTHindi\", \"ACTKorean\"]:\n",
    "    add = [\"ground_truth\", \"reconstruct\"] if metric==\"NAT\" else []\n",
    "    accent = metric[3:].lower()\n",
    "    \n",
    "    models = experiments[accent]\n",
    "    models = [\"___\".join(mn.split(\"/\")) for mn in models]\n",
    "    \n",
    "    df_list = []\n",
    "    df = pd.concat([results[metric][idx] for idx in range(len(results[metric]))], axis=0)\n",
    "    params = {(\"basic\", \"Test Name\"): list(set(list(df[(\"basic\", \"Test Name\")].unique())) - set(excluded_list))}\n",
    "    df = df[get_bool_base_on_conditions(df, params, True)]\n",
    "    if standardization:\n",
    "        for testid in df[(\"basic\", \"Test ID\")].unique():\n",
    "            a = df[get_bool_base_on_conditions(df, {(\"basic\", \"Test ID\"): [testid]}, True)]\n",
    "            col = (metric, \"score\")\n",
    "            df.loc[get_bool_base_on_conditions(df, {(\"basic\", \"Test ID\"): [testid]}, True), col]  = (a[col] - a[col].mean()) / a[col].std() \n",
    "    arrays = []\n",
    "    for mn in add+models:\n",
    "        params = {(\"basic\", \"model name\"): [mn]}\n",
    "        d = df[get_bool_base_on_conditions(df, params, True)]\n",
    "        values = d[(metric, \"score\")].values\n",
    "        mean = np.mean(values)\n",
    "        # ivl = st.t.interval(alpha=0.95, df=len(values)-1, loc=np.mean(values), scale=st.sem(values)) \n",
    "        ivl = st.t.interval(confidence=0.95, df=len(values)-1, loc=np.mean(values), scale=st.sem(values)) \n",
    "        ivl = (ivl[1]-ivl[0])/2\n",
    "        arrays += [[mean, ivl]]\n",
    "    df = pd.DataFrame(arrays, index=add+models, columns=[\"mean\", \"interval\"])\n",
    "    dfdir[metric] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "4d01c9fd-6f04-415e-b4aa-56398ed59d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_95428_row0_col0 {\n",
       "  background-color: rgb(0, 0, 0);\n",
       "}\n",
       "#T_95428_row1_col0 {\n",
       "  background-color: rgb(0, 0, 24);\n",
       "}\n",
       "#T_95428_row2_col0 {\n",
       "  background-color: rgb(0, 0, 202);\n",
       "}\n",
       "#T_95428_row3_col0 {\n",
       "  background-color: rgb(0, 0, 161);\n",
       "}\n",
       "#T_95428_row4_col0, #T_95428_row5_col0 {\n",
       "  background-color: rgb(0, 0, 252);\n",
       "}\n",
       "#T_95428_row6_col0 {\n",
       "  background-color: rgb(0, 0, 255);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_95428\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_95428_level0_col0\" class=\"col_heading level0 col0\" >mean</th>\n",
       "      <th id=\"T_95428_level0_col1\" class=\"col_heading level0 col1\" >interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_95428_level0_row0\" class=\"row_heading level0 row0\" >CMU-ARCTIC___SLT</th>\n",
       "      <td id=\"T_95428_row0_col0\" class=\"data row0 col0\" >5.375000</td>\n",
       "      <td id=\"T_95428_row0_col1\" class=\"data row0 col1\" >0.622019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_95428_level0_row1\" class=\"row_heading level0 row1\" >PD-AST___SLT___English</th>\n",
       "      <td id=\"T_95428_row1_col0\" class=\"data row1 col0\" >12.800000</td>\n",
       "      <td id=\"T_95428_row1_col1\" class=\"data row1 col1\" >19.409490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_95428_level0_row2\" class=\"row_heading level0 row2\" >L2-ARCTIC___HKK</th>\n",
       "      <td id=\"T_95428_row2_col0\" class=\"data row2 col0\" >66.777778</td>\n",
       "      <td id=\"T_95428_row2_col1\" class=\"data row2 col1\" >10.875891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_95428_level0_row3\" class=\"row_heading level0 row3\" >L2-ARCTIC___YDCK</th>\n",
       "      <td id=\"T_95428_row3_col0\" class=\"data row3 col0\" >54.300000</td>\n",
       "      <td id=\"T_95428_row3_col1\" class=\"data row3 col1\" >16.630403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_95428_level0_row4\" class=\"row_heading level0 row4\" >PD-AST___SLT___Korean</th>\n",
       "      <td id=\"T_95428_row4_col0\" class=\"data row4 col0\" >81.888889</td>\n",
       "      <td id=\"T_95428_row4_col1\" class=\"data row4 col1\" >5.872197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_95428_level0_row5\" class=\"row_heading level0 row5\" >PD-AST___HKK___Korean</th>\n",
       "      <td id=\"T_95428_row5_col0\" class=\"data row5 col0\" >82.111111</td>\n",
       "      <td id=\"T_95428_row5_col1\" class=\"data row5 col1\" >5.984322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_95428_level0_row6\" class=\"row_heading level0 row6\" >PD-AST___YDCK___Korean</th>\n",
       "      <td id=\"T_95428_row6_col0\" class=\"data row6 col0\" >82.777778</td>\n",
       "      <td id=\"T_95428_row6_col1\" class=\"data row6 col1\" >4.361434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28e190ac0>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dfdir[\"ACTKorean\"]\n",
    "df.style.apply(lambda x:apply_color_gradient(x, min_val=df[\"mean\"].min(), max_val=df[\"mean\"].max()), axis=None, subset=[\"mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc559f6e-25c3-4d12-bcfa-c5d07d5289dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
