{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1394,
   "id": "210d8635-8be2-4846-a7a6-a29db50c4843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import scipy.stats as st\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/shoahoshoaho/Git/cuhksz-phd/sho_util/pyfiles/\")\n",
    "from basic import get_bool_base_on_conditions\n",
    "\n",
    "def get_json(path):\n",
    "    with open(path, 'r') as j:\n",
    "         contents = json.loads(j.read())\n",
    "    return contents\n",
    "\n",
    "sr = 16000\n",
    "result_base_dir = \"./audio/20240815_spaccent/\"\n",
    "\n",
    "experiments = {\n",
    "    \"hindi\": [\n",
    "        \"CMU-ARCTIC/SLT\",\n",
    "        \"PD-AST/SLT/English\",\n",
    "        \"L2-ARCTIC/ASI\",\n",
    "        \"L2-ARCTIC/TNI\",\n",
    "        \"PD-AST/SLT/Hindi\",\n",
    "        \"PD-AST/ASI/Hindi\",\n",
    "        \"PD-AST/TNI/Hindi\",\n",
    "        \"VTN_fine-tuning_nocondition_gt2syn_hifiganmelhifiganmel_hubert_norepeating/100000\",\n",
    "        \"VTN_fine-tuning_nocondition_mix2synVCTK3hr_hifiganmelhifiganmel_hubert_norepeating/100000\",\n",
    "    ],\n",
    "    \"korean\": [\n",
    "        \"CMU-ARCTIC/SLT\",\n",
    "        \"PD-AST/SLT/English\",\n",
    "        \"L2-ARCTIC/HKK\",\n",
    "        \"L2-ARCTIC/YDCK\",\n",
    "        \"PD-AST/SLT/Korean\",\n",
    "        \"PD-AST/HKK/Korean\",\n",
    "        \"PD-AST/YDCK/Korean\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1395,
   "id": "b3b45315-7a33-4411-b530-968403dc056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_control_result(contents, name, sampleid, segment):\n",
    "    arrays = []\n",
    "    for idx, a in enumerate(contents):\n",
    "        if idx>=48:\n",
    "            continue\n",
    "        mn, fileid, emotion = a[\"TestID\"].split(\"---\")[-3:]\n",
    "        allocation = {item[0]: item[2] for item in a[\"PresentationOrder\"].split(\", \")}\n",
    "        res = [allocation[key] for key in a[\"Preference\"]]\n",
    "        array = [mn, fileid, emotion, *res]\n",
    "        arrays += [array]\n",
    "\n",
    "    columns = [\"model name\", \"file id\", \"emotion\", \"Lowest Prediction\", \"Highest Prediction\"]\n",
    "    sampledf = pd.DataFrame(np.array(arrays), columns=columns)\n",
    "    samplearrays = []\n",
    "    for mn in modelnames:\n",
    "        for fileid in sampledf[\"file id\"].unique():\n",
    "            params = {\"model name\": [mn], \"file id\": [fileid]}\n",
    "            modeldf = sampledf[get_bool_base_on_conditions(sampledf, params)]\n",
    "            if len(modeldf)>0:\n",
    "                int_array = []\n",
    "                for emotion in emos:\n",
    "                    params = {\"emotion\": [emotion]}\n",
    "                    emotiondf = modeldf[get_bool_base_on_conditions(modeldf, params)]\n",
    "                    a = [(emotiondf[\"Lowest Prediction\"]==label).sum() for label in intensitylabels]\n",
    "                    b = [(emotiondf[\"Highest Prediction\"]==label).sum() for label in intensitylabels]\n",
    "                    int_array += [a + b]\n",
    "                array = list(np.array(int_array).reshape(-1)) + list(np.sum(np.array(int_array), axis=0))\n",
    "            else:\n",
    "                array = [None]*30\n",
    "            samplearrays += [[name, sampleid, fileid, mn, *array]]\n",
    "\n",
    "    columns = []\n",
    "    for cl in [\"Test Name\", \"Test ID\", \"File ID\", \"model name\"]:\n",
    "        columns += [(\"basic\", \"\", cl)]\n",
    "    for emotion in emos + [\"total\"]:\n",
    "        for key in [\"LP\", \"HP\"]:\n",
    "            for label in intensitylabels:\n",
    "                columns += [(f\"{segment}-level control\", emotion, f\"{key}-{label}\")]\n",
    "    result = pd.DataFrame(np.array(samplearrays), columns=pd.MultiIndex.from_tuples(columns))\n",
    "    return result\n",
    "\n",
    "def get_mushra_result(contents, name, sampleid, metric):\n",
    "    arrays = []\n",
    "    for idx, a in enumerate(contents):\n",
    "        if idx>=100:\n",
    "            continue\n",
    "        if len(a)==1:\n",
    "            continue\n",
    "        _, fileid = a[\"TestID\"].split(\"---\")\n",
    "        ratings = a[\"rating\"]\n",
    "        arrays += [[name, sampleid, fileid, key, ratings[key]]for key in ratings]\n",
    "    columns = []\n",
    "    for cl in [\"Test Name\", \"Test ID\", \"File ID\", \"model name\"]:\n",
    "        columns += [(\"basic\",  cl)]\n",
    "    for label in [f\"{metric}\"]:\n",
    "        columns += [(metric, \"score\")]\n",
    "    result = pd.DataFrame(np.array(arrays), columns=pd.MultiIndex.from_tuples(columns))\n",
    "    result.loc[:, [metric]] = result.loc[:, [metric]].values.astype(float)\n",
    "    return result\n",
    "\n",
    "def get_contents(path):\n",
    "    contents = get_json(path)\n",
    "    name = contents[-1][\"UserName\"]\n",
    "    sampleid = path[:-5].split(\"_\")[-1]\n",
    "    return contents, name, sampleid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1396,
   "id": "e367e1b6-73b0-4f3e-bf36-592ea946fe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contents(path):\n",
    "    contents = get_json(path)\n",
    "    name = contents[-1][\"UserName\"]\n",
    "    sampleid = path[:-5].split(\"_\")[-1]\n",
    "    return contents, name, sampleid\n",
    "\n",
    "def get_mushra_result(contents, name, sampleid, metric):\n",
    "    arrays = []\n",
    "    for idx, a in enumerate(contents):\n",
    "        if idx>=100:\n",
    "            continue\n",
    "        if len(a)==1:\n",
    "            continue\n",
    "        _, fileid = a[\"TestID\"].split(\"---\")\n",
    "        ratings = a[\"rating\"]\n",
    "        arrays += [[name, sampleid, fileid, key, ratings[key]]for key in ratings]\n",
    "    columns = []\n",
    "    for cl in [\"Test Name\", \"Test ID\", \"File ID\", \"model name\"]:\n",
    "        columns += [(\"basic\",  cl)]\n",
    "    for label in [f\"{metric}\"]:\n",
    "        columns += [(metric, \"score\")]\n",
    "    result = pd.DataFrame(np.array(arrays), columns=pd.MultiIndex.from_tuples(columns))\n",
    "    result.loc[:, [metric]] = result.loc[:, [metric]].values.astype(float)\n",
    "    return result\n",
    "\n",
    "def get_diffs(result):\n",
    "    diffs = []\n",
    "    params = {(\"basic\", \"model name\"): [a for a in list(set(list(result[(\"basic\", \"model name\")].unique())) - set(excluded_list)) if \"---2\" in a]}\n",
    "    df = result[get_bool_base_on_conditions(result, params, True)]\n",
    "    for array in df.values:\n",
    "        _, _, fileid, mn, _ = array\n",
    "        mn2 = mn.split(\"---\")[0]\n",
    "        params = {(\"basic\", \"File ID\"): [fileid], (\"basic\", \"model name\"):[mn, mn2]}\n",
    "        result[get_bool_base_on_conditions(result, params, True)]\n",
    "        scores = result[get_bool_base_on_conditions(result, params, True)].values[:, -1]\n",
    "        diffs += [np.abs(scores[0]-scores[1])]\n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1397,
   "id": "02dca659-e64b-49fc-a217-a12ea7328a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240829-1731_Reichan_68838ed4 Reichan ACTHindi 19.875\n",
      "20240830-1237_Sho_54664130 Sho ACTHindi 3.875\n",
      "20240830-1659_Sho_506d3899 Sho ACTKorean 11.375\n",
      "20240902-0739_Reichan_22943887 Reichan NATHindi 8.75\n",
      "20240902-0808_Reichan_186cc5f8 Reichan NATKorean 12.25\n",
      "20240902-0820_Reichan_f7fe747 Reichan ACTKorean 8.25\n",
      "Hindi-1-124457_  NATHindi 25.0\n",
      "Hindi-1-130728_  ACTHindi 15.533333333333333\n",
      "Hindi-2-043259_ rosemary Huang NATHindi 0.6666666666666666\n",
      "Hindi-2-045333_ rosemary Huang ACTHindi 4.466666666666667\n",
      "Hindi-3-102342_ 777 NATHindi 12.866666666666667\n",
      "Hindi-3-104035_ 444 ACTHindi 16.4\n",
      "Hindi-4-104014_ Coco NATKorean 9.666666666666666\n",
      "Hindi-4-105754_ Coco ACTKorean 3.6666666666666665\n",
      "Hindi-5-093328_ flora ACTHindi 4.866666666666666\n",
      "Hindi-5-120547_ flora NATHindi 3.2\n",
      "Hindi-5-add-103943_ flora ACTHindi 5.8\n",
      "Hindi-5-add-120547_ flora NATHindi 3.2\n",
      "Korean-1-193327_  NATKorean 9.666666666666666\n",
      "Korean-1-220327_  ACTKorean 1.0666666666666667\n",
      "Korean-2-155340_  NATKorean 5.4\n",
      "Korean-2-171041_  ACTKorean 1.2\n",
      "Korean-3-124457_  NATHindi 25.0\n",
      "Korean-3-130728_  ACTHindi 15.533333333333333\n",
      "Korean-3-add-134606_  NATKorean 8.666666666666666\n",
      "Korean-3-add-135945_  ACTKorean 8.133333333333333\n",
      "Korean-4-101351_ Coco NATHindi 3.8666666666666667\n",
      "Korean-4-102845_ Coco ACTHindi 10.6\n",
      "Korean-5-093609_ flora ACTKorean 9.466666666666667\n",
      "Korean-5-122039_ flora NATKorean 4.066666666666666\n",
      "Korean-5-add-182021_  NATKorean 2.2\n",
      "Korean-5-add-183653_  ACTKorean 7.8\n",
      "test_ACTHindi  ACTHindi 15.533333333333333\n",
      "test_ACTKorean  ACTKorean 1.0666666666666667\n",
      "test_NATHindi  NATHindi 25.0\n",
      "test_NATKorean  NATKorean 9.666666666666666\n"
     ]
    }
   ],
   "source": [
    "resultfiles = glob.glob(f\"./web_service/results/*.json\")\n",
    "resultfiles.sort()\n",
    "\n",
    "not_found = []\n",
    "results = {key: [] for key in [\"NATHindi\", \"ACTHindi\", \"NATKorean\", \"ACTKorean\"]}\n",
    "filenames = {key: [] for key in [\"NATHindi\", \"ACTHindi\", \"NATKorean\", \"ACTKorean\"]}\n",
    "for path in resultfiles:\n",
    "    contents, name, sampleid = get_contents(path)\n",
    "    testtype = contents[0][\"TestID\"].split(\"---\")[0]\n",
    "    if testtype==\"NATHindi\":\n",
    "        result = get_mushra_result(contents, name, sampleid, testtype)\n",
    "    elif testtype==\"ACTHindi\":\n",
    "        result = get_mushra_result(contents, name, sampleid, testtype)\n",
    "    if testtype==\"NATKorean\":\n",
    "        result = get_mushra_result(contents, name, sampleid, testtype)\n",
    "    elif testtype==\"ACTKorean\":\n",
    "        result = get_mushra_result(contents, name, sampleid, testtype)\n",
    "    diffs = get_diffs(result)\n",
    "    fn = os.path.basename(path).split(\".\")[0]\n",
    "    print(fn, name, testtype, np.mean(diffs))\n",
    "    result[(\"basic\", \"model name\")] = [a.split(\"---\")[0] for a in result[(\"basic\", \"model name\")].values]\n",
    "    results[testtype] += [result]\n",
    "    filenames[testtype] += [fn]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79e4bb9-eef7-442b-9d13-57bd22e04635",
   "metadata": {},
   "source": [
    "# Check Individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c600f76-8e75-4227-8ea9-c38ffd992048",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [\n",
    "    \"20240902-0739_Reichan_22943887\" # Only check the noise\n",
    "    \"Hindi-1-124457_\", # Too unreliable (different scores for the same audio samples)\n",
    "    \"Hindi-5-093328_\", # Random selection \n",
    "    \"Hindi-5-120547_\", # Random selection\n",
    "    \"Korean-3-124457_\", # Retaken\n",
    "    \"Korean-3-130728_\", # Retaken\n",
    "    \"Korean-4-101351_\", # Only check the noise\n",
    "    \"Korean-5-093609_\", # Random selection\n",
    "    \"Korean-5-122039_\", # Random selection\n",
    "    \"Korean-5-add-182021_\", # Only check the noise (too low for the ground-truth)\n",
    "    \"test\",\n",
    "]\n",
    "for metric in results:\n",
    "    alive = [a for a in filenames[metric] if not(a in errors)]\n",
    "    print(metric, len(alive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1400,
   "id": "f463430b-7bbc-4abe-8c2a-d3810bdb7129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240902-0808_Reichan_186cc5f8\n",
      "Reichan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(basic, Test Name)</th>\n",
       "      <th>(basic, model name)</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">Reichan</th>\n",
       "      <th>CMU-ARCTIC___SLT</th>\n",
       "      <td>49.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2-ARCTIC___HKK</th>\n",
       "      <td>45.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2-ARCTIC___YDCK</th>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PD-AST___HKK___Korean</th>\n",
       "      <td>25.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PD-AST___SLT___English</th>\n",
       "      <td>45.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PD-AST___SLT___Korean</th>\n",
       "      <td>33.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PD-AST___YDCK___Korean</th>\n",
       "      <td>43.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               score\n",
       "(basic, Test Name) (basic, model name)              \n",
       "Reichan            CMU-ARCTIC___SLT        49.333333\n",
       "                   L2-ARCTIC___HKK         45.222222\n",
       "                   L2-ARCTIC___YDCK        76.000000\n",
       "                   PD-AST___HKK___Korean   25.363636\n",
       "                   PD-AST___SLT___English  45.333333\n",
       "                   PD-AST___SLT___Korean   33.250000\n",
       "                   PD-AST___YDCK___Korean  43.375000"
      ]
     },
     "execution_count": 1400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "metric = \"NATKorean\"\n",
    "\n",
    "result = results[metric][idx]\n",
    "fn = filenames[metric][idx]\n",
    "print(fn)\n",
    "print(result[(\"basic\", \"Test Name\")][0])\n",
    "result.groupby([(\"basic\",\"Test Name\"), (\"basic\",\"model name\")]).mean()[metric]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8c06c5-b23f-4679-8f9f-0b7347afbaf5",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1401,
   "id": "3457e9de-c74e-43fd-92d3-bb2de20d3c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_gradient(val, min_val=-1, max_val=1, color='red'):\n",
    "    if val < min_val: val = min_val\n",
    "    if val > max_val: val = max_val\n",
    "    normalized_val = (val - min_val) / (max_val - min_val)\n",
    "    \n",
    "    if color == 'red':\n",
    "        red_intensity = int(255 * normalized_val)\n",
    "        return f'background-color: rgb({red_intensity}, 0, 0)'\n",
    "    elif color == 'green':\n",
    "        green_intensity = int(255 * normalized_val)\n",
    "        return f'background-color: rgb(0, {green_intensity}, 0)'\n",
    "    elif color == 'blue':\n",
    "        blue_intensity = int(255 * normalized_val)\n",
    "        return f'background-color: rgb(0, 0, {blue_intensity})'\n",
    "    else:\n",
    "        return 'background-color: none'\n",
    "\n",
    "def apply_color_gradient(df, min_val=0, max_val=1.0):\n",
    "    \"\"\"\n",
    "    df.style.apply(lambda x:apply_color_gradient(x, min_val=0, max_val=100), axis=None)\n",
    "    \"\"\"\n",
    "    styles = df.copy()\n",
    "    for col in styles.columns:\n",
    "        color = 'red' if \"LP\" in col else \"green\"\n",
    "        color = \"blue\" if col==\"mean\" else color\n",
    "        styles[col] = df[col].apply(color_gradient, min_val=min_val, max_val=max_val, color=color)\n",
    "    return styles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5402b1fd-653e-461e-bf9c-70303b020e46",
   "metadata": {},
   "source": [
    "- MUSHRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1402,
   "id": "d2f7bb1f-1ff3-4fb8-8151-4b37369b90af",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardization = False\n",
    "excluded_list = []\n",
    "\n",
    "dfdir = {}\n",
    "for metric in [\"NATHindi\", \"ACTHindi\", \"NATKorean\", \"ACTKorean\"]:\n",
    "    add = [\"ground_truth\", \"reconstruct\"] if metric==\"NAT\" else []\n",
    "    accent = metric[3:].lower()\n",
    "    \n",
    "    models = experiments[accent]\n",
    "    models = [\"___\".join(mn.split(\"/\")) for mn in models]\n",
    "    \n",
    "    idxlist = [a for a in range(len(filenames[metric])) if not(filenames[metric][a] in errors)]\n",
    "    df_list = []\n",
    "    df = pd.concat([results[metric][idx] for idx in idxlist], axis=0)\n",
    "    params = {(\"basic\", \"Test Name\"): list(set(list(df[(\"basic\", \"Test Name\")].unique())) - set(excluded_list))}\n",
    "    df = df[get_bool_base_on_conditions(df, params, True)]\n",
    "    if standardization:\n",
    "        for testid in df[(\"basic\", \"Test ID\")].unique():\n",
    "            a = df[get_bool_base_on_conditions(df, {(\"basic\", \"Test ID\"): [testid]}, True)]\n",
    "            col = (metric, \"score\")\n",
    "            df.loc[get_bool_base_on_conditions(df, {(\"basic\", \"Test ID\"): [testid]}, True), col]  = (a[col] - a[col].mean()) / a[col].std() \n",
    "    arrays = []\n",
    "    for mn in add+models:\n",
    "        params = {(\"basic\", \"model name\"): [mn]}\n",
    "        d = df[get_bool_base_on_conditions(df, params, True)]\n",
    "        values = d[(metric, \"score\")].values\n",
    "        mean = np.mean(values)\n",
    "        # ivl = st.t.interval(alpha=0.95, df=len(values)-1, loc=np.mean(values), scale=st.sem(values)) \n",
    "        ivl = st.t.interval(confidence=0.95, df=len(values)-1, loc=np.mean(values), scale=st.sem(values)) \n",
    "        ivl = (ivl[1]-ivl[0])/2\n",
    "        arrays += [[mean, ivl]]\n",
    "    df = pd.DataFrame(arrays, index=add+models, columns=[\"mean\", \"interval\"])\n",
    "    dfdir[metric] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1403,
   "id": "4d01c9fd-6f04-415e-b4aa-56398ed59d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9043f_row0_col0 {\n",
       "  background-color: rgb(0, 0, 189);\n",
       "}\n",
       "#T_9043f_row1_col0 {\n",
       "  background-color: rgb(0, 0, 147);\n",
       "}\n",
       "#T_9043f_row2_col0 {\n",
       "  background-color: rgb(0, 0, 255);\n",
       "}\n",
       "#T_9043f_row3_col0 {\n",
       "  background-color: rgb(0, 0, 225);\n",
       "}\n",
       "#T_9043f_row4_col0 {\n",
       "  background-color: rgb(0, 0, 136);\n",
       "}\n",
       "#T_9043f_row5_col0 {\n",
       "  background-color: rgb(0, 0, 231);\n",
       "}\n",
       "#T_9043f_row6_col0 {\n",
       "  background-color: rgb(0, 0, 213);\n",
       "}\n",
       "#T_9043f_row7_col0 {\n",
       "  background-color: rgb(0, 0, 0);\n",
       "}\n",
       "#T_9043f_row8_col0 {\n",
       "  background-color: rgb(0, 0, 118);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9043f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9043f_level0_col0\" class=\"col_heading level0 col0\" >mean</th>\n",
       "      <th id=\"T_9043f_level0_col1\" class=\"col_heading level0 col1\" >interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9043f_level0_row0\" class=\"row_heading level0 row0\" >CMU-ARCTIC___SLT</th>\n",
       "      <td id=\"T_9043f_row0_col0\" class=\"data row0 col0\" >76.475904</td>\n",
       "      <td id=\"T_9043f_row0_col1\" class=\"data row0 col1\" >3.823068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9043f_level0_row1\" class=\"row_heading level0 row1\" >PD-AST___SLT___English</th>\n",
       "      <td id=\"T_9043f_row1_col0\" class=\"data row1 col0\" >70.951807</td>\n",
       "      <td id=\"T_9043f_row1_col1\" class=\"data row1 col1\" >4.070006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9043f_level0_row2\" class=\"row_heading level0 row2\" >L2-ARCTIC___ASI</th>\n",
       "      <td id=\"T_9043f_row2_col0\" class=\"data row2 col0\" >85.165644</td>\n",
       "      <td id=\"T_9043f_row2_col1\" class=\"data row2 col1\" >1.870505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9043f_level0_row3\" class=\"row_heading level0 row3\" >L2-ARCTIC___TNI</th>\n",
       "      <td id=\"T_9043f_row3_col0\" class=\"data row3 col0\" >81.294444</td>\n",
       "      <td id=\"T_9043f_row3_col1\" class=\"data row3 col1\" >2.757377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9043f_level0_row4\" class=\"row_heading level0 row4\" >PD-AST___SLT___Hindi</th>\n",
       "      <td id=\"T_9043f_row4_col0\" class=\"data row4 col0\" >69.510204</td>\n",
       "      <td id=\"T_9043f_row4_col1\" class=\"data row4 col1\" >3.994415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9043f_level0_row5\" class=\"row_heading level0 row5\" >PD-AST___ASI___Hindi</th>\n",
       "      <td id=\"T_9043f_row5_col0\" class=\"data row5 col0\" >82.122340</td>\n",
       "      <td id=\"T_9043f_row5_col1\" class=\"data row5 col1\" >2.359116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9043f_level0_row6\" class=\"row_heading level0 row6\" >PD-AST___TNI___Hindi</th>\n",
       "      <td id=\"T_9043f_row6_col0\" class=\"data row6 col0\" >79.640719</td>\n",
       "      <td id=\"T_9043f_row6_col1\" class=\"data row6 col1\" >2.817142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9043f_level0_row7\" class=\"row_heading level0 row7\" >VTN_fine-tuning_nocondition_gt2syn_hifiganmelhifiganmel_hubert_norepeating___100000</th>\n",
       "      <td id=\"T_9043f_row7_col0\" class=\"data row7 col0\" >51.477273</td>\n",
       "      <td id=\"T_9043f_row7_col1\" class=\"data row7 col1\" >3.726315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9043f_level0_row8\" class=\"row_heading level0 row8\" >VTN_fine-tuning_nocondition_mix2synVCTK3hr_hifiganmelhifiganmel_hubert_norepeating___100000</th>\n",
       "      <td id=\"T_9043f_row8_col0\" class=\"data row8 col0\" >67.179775</td>\n",
       "      <td id=\"T_9043f_row8_col1\" class=\"data row8 col1\" >3.434260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x17664b1f0>"
      ]
     },
     "execution_count": 1403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode = \"NATHindi\"\n",
    "df = dfdir[mode]\n",
    "df.style.apply(lambda x:apply_color_gradient(x, min_val=df[\"mean\"].min(), max_val=df[\"mean\"].max()), axis=None, subset=[\"mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1404,
   "id": "84888c33-cdd1-49d6-80a4-2cec6a382a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in dfdir:\n",
    "    savefile = f\"summary/{mode}.csv\"\n",
    "    df = dfdir[mode]\n",
    "    df.to_csv(savefile)\n",
    "    d = pd.read_csv(savefile, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd11632-8c56-4580-92a0-83b5a55d9c40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
